{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Cheat Sheet de Machine Learning com Scikit-Learn e Pandas**"
      ],
      "metadata": {
        "id": "OnisX8PuMzkH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Pré-processamento**"
      ],
      "metadata": {
        "id": "J1w8ZvIHM1j-"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "by3B2VsYIt-y"
      },
      "source": [
        "### **Divisao treino/teste (`sklearn`)**\n",
        "\n",
        "```python\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Dados fictícios\n",
        "X = features\n",
        "y = target\n",
        "\n",
        "# Dividindo os dados em treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "  X, y,\n",
        "  test_size=0.2,\n",
        "  random_state=42\n",
        ")\n",
        "\n",
        "# Divisão com classes desbalanceadas na resposta\n",
        "stratify=y  # opção que mantém proporção das classes\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **OneHoteEncoding  e LabelEncoding**\n",
        "\n",
        "#### `pd.get_dummies()`\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "\n",
        "# Dados fictícios\n",
        "df = pd.DataFrame({'pay_method': ['credit', 'debit', 'pay_online']})\n",
        "\n",
        "# Codificação (novas colunas True/False)\n",
        "df_encoded = pd.get_dummies(df, columns=['pay_method'])\n",
        "```\n",
        "\n",
        "### `OneHotEncoder`\n",
        "\n",
        "```python\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import numpy as np\n",
        "\n",
        "# Dados fictícios\n",
        "\n",
        "# Codificação para Arrays:\n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "X = np.array(['credit', 'debit', 'pay_online']).reshape(-1, 1)\n",
        "X_encoded = encoder.fit_transform(X)\n",
        "\n",
        "# Codificação para Dataframes:\n",
        "encoder = OneHotEncoder(sparse_output=False).set_output(transform=\"pandas\")\n",
        "data_cat = data[['credit', 'debit', 'pay_online']]\n",
        "df_encoded = encoder.fit_transform(data_cat)\n",
        "```\n",
        "\n",
        "#### `LabelEncoding`\n",
        "\n",
        " ```python\n",
        " from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "#  Codificação (rótulos para cada categoria)\n",
        "encoder = LabelEncoder()\n",
        "dados['categoria_cod'] = encoder.fit_transform(dados['categoria'])\n",
        "# Visualização\n",
        "print(tips['categoria'].unique())\n",
        "print(tips['categorias_cod'].unique())\n",
        " ```"
      ],
      "metadata": {
        "id": "3gBXnloWOAB5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Scaling com `StandardScaler`**\n",
        "\n",
        "```python\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Dados fictícios\n",
        "scaler = StandardScaler()\n",
        "X = dados[['colunas_numericas']].copy()\n",
        "\n",
        "# Normalização\n",
        "X['col_std'] = scaler.fit_transform(X[['col']])\n",
        "```\n",
        "\n",
        "### Scaling com `MinMaxScaler`\n",
        "\n",
        "```python\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Dados fictícios\n",
        "scaler = MinMaxScaler()\n",
        "X = dados[['colunas_numericas']].copy()\n",
        "\n",
        "# Normalização\n",
        "X['col_std'] = scaler.fit_transform(X[['col']])\n",
        "```"
      ],
      "metadata": {
        "id": "48yOZGJWOENu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Algoritmos**"
      ],
      "metadata": {
        "id": "X_wSjzVtMsbx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 7. K-means\n",
        "\n",
        "```python\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Dados fictícios\n",
        "X = ...\n",
        "\n",
        "# Treinamento do modelo\n",
        "kmeans = KMeans(n_clusters=3, random_state=42)\n",
        "kmeans.fit(X)\n",
        "\n",
        "# Predições\n",
        "labels = kmeans.predict(X)\n",
        "```\n",
        "\n",
        "## 8. Simple Linear Regression (`sklearn`)\n",
        "\n",
        "```python\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Dados fictícios\n",
        "X, y = ..., ...\n",
        "\n",
        "# Treinamento do modelo\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Predições\n",
        "y_pred = model.predict(X)\n",
        "```\n",
        "\n",
        "## 9. Polynomial Regression (`sklearn`)\n",
        "\n",
        "```python\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Dados fictícios\n",
        "X, y = ..., ...\n",
        "\n",
        "# Transformação polinomial\n",
        "poly = PolynomialFeatures(degree=3)\n",
        "X_poly = poly.fit_transform(X)\n",
        "\n",
        "# Treinamento do modelo\n",
        "model = LinearRegression()\n",
        "model.fit(X_poly, y)\n",
        "\n",
        "# Predições\n",
        "y_pred = model.predict(X_poly)\n",
        "```\n",
        "\n",
        "## 10. Logistic Regression (`sklearn`)\n",
        "\n",
        "```python\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Dados fictícios\n",
        "X, y = ..., ...\n",
        "\n",
        "# Treinamento do modelo\n",
        "model = LogisticRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Predições\n",
        "y_pred = model.predict(X)\n",
        "```\n",
        "\n",
        "## 11. Decision Tree Classifier (`sklearn`)\n",
        "\n",
        "```python\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Dados fictícios\n",
        "X, y = ..., ...\n",
        "\n",
        "# Treinamento do modelo\n",
        "model = DecisionTreeClassifier()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Predições\n",
        "y_pred = model.predict(X)\n",
        "```\n",
        "\n",
        "## 12. Decision Tree Regressor (`sklearn`)\n",
        "\n",
        "```python\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "# Dados fictícios\n",
        "X, y = ..., ...\n",
        "\n",
        "# Treinamento do modelo\n",
        "model = DecisionTreeRegressor()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Predições\n",
        "y_pred = model.predict(X)\n",
        "```\n",
        "\n",
        "## 13. Random Forest\n",
        "\n",
        "```python\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Dados fictícios\n",
        "X, y = ..., ...\n",
        "\n",
        "# Treinamento do modelo\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(X, y)\n",
        "\n",
        "# Predições\n",
        "y_pred = model.predict(X)\n",
        "```\n",
        "\n",
        "## 14. Naive Bayes\n",
        "\n",
        "### Gaussian Naive Bayes\n",
        "\n",
        "```python\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "# Dados fictícios\n",
        "X, y = ..., ...\n",
        "\n",
        "# Treinamento do modelo\n",
        "model = GaussianNB()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Predições\n",
        "y_pred = model.predict(X)\n",
        "```\n",
        "\n",
        "## 15. K-Nearest Neighbors (KNN)\n",
        "\n",
        "```python\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Dados fictícios\n",
        "X, y = ..., ...\n",
        "\n",
        "# Treinamento do modelo\n",
        "model = KNeighborsClassifier(n_neighbors=5)\n",
        "model.fit(X, y)\n",
        "\n",
        "# Predições\n",
        "y_pred = model.predict(X)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "xtdOzaG4MvFf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Validação**"
      ],
      "metadata": {
        "id": "vRTWZJbiNIJf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Métricas de Regressão com `sklearn`**\n",
        "\n",
        "```python\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Dados fictícios\n",
        "y_true = ...\n",
        "y_pred = ...\n",
        "\n",
        "# Métricas\n",
        "mse = mean_squared_error(y_true, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_true, y_pred)\n",
        "```\n",
        "\n",
        "### **Métricas de Classificação com `sklearn`**\n",
        "\n",
        "```python\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
        "\n",
        "# Dados fictícios\n",
        "y_true = ...\n",
        "y_pred = ...\n",
        "\n",
        "# Métricas\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "precision = precision_score(y_true, y_pred, average='binary')\n",
        "recall = recall_score(y_true, y_pred, average='binary')\n",
        "f1 = f1_score(y_true, y_pred, average='binary')\n",
        "conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "report = classification_report(y_true, y_pred)\n",
        "```\n"
      ],
      "metadata": {
        "id": "AqbVW_ISNKlG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Exportando um modelo**"
      ],
      "metadata": {
        "id": "gtsz6rLVNfjm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "```python\n",
        "import pickle\n",
        "\n",
        "with open('rf.pkl', 'wb') as file:\n",
        "  pickle.dump(rf, file)\n",
        "```\n",
        "\n",
        "```python\n",
        "with open('rf.pkl', 'rb') as file:\n",
        "    loaded_model = pickle.load(file)\n",
        "loaded_model\n",
        "```\n"
      ],
      "metadata": {
        "id": "dq0_MdJ2NdkH"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}